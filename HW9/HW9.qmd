---
title: "HW#10"
author: "Yigit Ali Karadogan"
format: html
editor: visual
---

## HW#10

### Question 12

> Suppose that you wish to classify an observation $X \in \mathbb{R}$ into `apples` and `oranges`. You fit a logistic regression model and find that

> $$
> \hat{Pr}(Y=orange|X=x) = 
> \frac{\exp(\hat\beta_0 + \hat\beta_1x)}{1 + \exp(\hat\beta_0 + \hat\beta_1x)}
> $$

> Your friend fits a logistic regression model to the same data using the *softmax* formulation, and finds that

> $$
> \hat{Pr}(Y=orange|X=x) = 
> \frac{\exp(\hat\alpha_{orange0} + \hat\alpha_{orange1}x)}
> {\exp(\hat\alpha_{orange0} + \hat\alpha_{orange1}x) + \exp(\hat\alpha_{apple0} + \hat\alpha_{apple1}x)}
> $$
>
> a.  What is the log odds of `orange` versus `apple` in your model?

The log odds: $\hat\beta_0 + \hat\beta_1x$

> b.  What is the log odds of `orange` versus `apple` in your friend's model?

log odds of our friend's model is:

$$
(\hat\alpha_{orange0} - \hat\alpha_{apple0}) + (\hat\alpha_{orange1} - \hat\alpha_{apple1})x
$$

> c.  Suppose that in your model, $\hat\beta_0 = 2$ and $\hat\beta = −1$. What are the coefficient estimates in your friend's model? Be as specific as possible.

We can say that in our friend's model $\hat\alpha_{orange0} - \hat\alpha_{apple0} = 2$ and $\hat\alpha_{orange1} - \hat\alpha_{apple1} = -1$.

We are unable to know the values of each parameter.

> d.  Now suppose that you and your friend fit the same two models on a different data set. This time, your friend gets the coefficient estimates $\hat\alpha_{orange0} = 1.2$, $\hat\alpha_{orange1} = −2$, $\hat\alpha_{apple0} = 3$, $\hat\alpha_{apple1} = 0.6$. What are the coefficient estimates in your model?

The coefficients in our model are: $\hat\beta_0 = 1.2 - 3 = -1.8$, $\hat\beta_1 = -2 - 0.6 = -2.6$

> e.  Finally, suppose you apply both models from (d) to a data set with 2,000 test observations. What fraction of the time do you expect the predicted class labels from your model to agree with those from your friend's model? Explain your answer.

Both models should perfectly agree since they are identical with different parameterization.

### Question 14

```{r}
library(pander)
library(ISLR2)
```

> a.  Create a binary variable, `mpg01`, that contains a 1 if `mpg` contains a value above its median, and a 0 if `mpg` contains a value below its median. You can compute the median using the `median()` function. Note you may find it helpful to use the `data.frame()` function to create a single data set containing both `mpg01` and the other `Auto` variables.

```{r}
x <- cbind(Auto[, -1], data.frame("mpg01" = Auto$mpg > median(Auto$mpg)))
```

> b.  Explore the data graphically in order to investigate the association between `mpg01` and the other features. Which of the other features seem most likely to be useful in predicting `mpg01`? Scatterplots and boxplots may be useful tools to answer this question. Describe your findings.

```{r}
par(mfrow = c(2, 4))
for (i in 1:7) hist(x[, i], breaks = 20, main = colnames(x)[i])

par(mfrow = c(2, 4))
for (i in 1:7) boxplot(x[, i] ~ x$mpg01, main = colnames(x)[i])

pairs(x[, 1:7])
```

Most variables show an association with `mpg01` category, and several variables are colinear.

> c.  Split the data into a training set and a test set.

```{r}
set.seed(1)
train <- sample(seq_len(nrow(x)), nrow(x) * 2/3)
```

> d.  Perform LDA on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (b). What is the test error of the model obtained?

```{r}
library(MASS)
sort(sapply(1:7, function(i) {
  setNames(abs(t.test(x[, i] ~ x$mpg01)$statistic), colnames(x)[i])
}))

fit <- lda(mpg01 ~ cylinders + weight + displacement, data = x[train, ])
pred <- predict(fit, x[-train, ], type = "response")$class
mean(pred != x[-train, ]$mpg01)
```

> e.  Perform QDA on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (b). What is the test error of the model obtained?

```{r}
fit <- qda(mpg01 ~ cylinders + weight + displacement, data = x[train, ])
pred <- predict(fit, x[-train, ], type = "response")$class
mean(pred != x[-train, ]$mpg01)
```

> f.  Perform logistic regression on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (b). What is the test error of the model obtained?

```{r}
fit <- glm(mpg01 ~ cylinders + weight + displacement, data = x[train, ], family = binomial)
pred <- predict(fit, x[-train, ], type = "response") > 0.5
mean(pred != x[-train, ]$mpg01)
```

> g.  Perform naive Bayes on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (b). What is the test error of the model obtained?

```{r}
library(e1071)
fit <- naiveBayes(mpg01 ~ cylinders + weight + displacement, data = x[train, ])
pred <- predict(fit, x[-train, ], type = "class")
mean(pred != x[-train, ]$mpg01)
```

> h.  Perform KNN on the training data, with several values of $K$, in order to predict `mpg01`. Use only the variables that seemed most associated with `mpg01` in (b). What test errors do you obtain? Which value of $K$ seems to perform the best on this data set?

```{r}
library(class)
res <- sapply(1:50, function(k) {
  fit <- knn(x[train, c(1, 4, 2)], x[-train, c(1, 4, 2)], x$mpg01[train], k = k)
  mean(fit != x[-train, ]$mpg01)
})
names(res) <- 1:50
plot(res, type = "o")
res[which.min(res)]
```
